import cv2
import numpy as np
from keras.models import load_model
from sklearn.neighbors import KNeighborsClassifier
from scipy.stats import *
import h5py
from keras.models import load_model


def preprocess_image(image):
    with h5py.File("C:\\Users\\amirp\\Desktop\\Studies\\שנה ג\\Usd counterfeit fixed\\Usd counterfeit\\my_model.h5", 'r') as f:
    # Load the model architecture
        model = load_model(f, compile=False)

    X = df.iloc[:, :-1].values
    y = df.iloc[:, -1].values
    # Resize the image to 64x64 pixels
    resized_image = cv2.resize(image, (64, 64))
    # Convert the image to grayscale
    gray_image = cv2.cvtColor(resized_image, cv2.COLOR_RGB2GRAY)
    # Flatten the image to a 1D array
    flattened_image = gray_image.flatten()
    # Normalize the image by dividing each pixel value by 255
    normalized_image = flattened_image / 255.0
    # Add two extra zeros to the end of the flattened image to make it a 1D array of four features
    feature_vector = np.concatenate([normalized_image, [0, 0]])
    # Return the flattened array of four features
    
    ##########################
    var = np.var(flattened_image)/1372
    skewness = skew(flattened_image.reshape(-1))
    kurt = kurtosis(flattened_image.reshape(-1))
    hist, _ = np.histogram(flattened_image, bins=256)
    entropy_val = entropy(hist)

    # Create a KNN classifier object
    k = 5  # set the number of nearest neighbors to consider
    clf = KNeighborsClassifier(n_neighbors=k)

    # Fit the classifier on the training data
    clf.fit(X, y)

    # Predict the class label for the image
    img_features = [[var, skewness, kurt, entropy_val]]
    predicted_class = clf.predict(img_features)

    # Print the predicted class label
    print("Predicted Class Label:", predicted_class)
    print("Predicted Class Probabilities 0 for fake|1 for original")
    print("var:", var)
    print("ske:", skewness)
    print("kurt Class Label:", kurt)
    print("entropy_val:", entropy_val)
    
    # output the prediction
    if predicted_class <= 0.6: # it should be 0.5 because of the mean value of the training model.
        print("Fake note")
    else:
        print("Real note")
        
    #detect_image(predicted_class,path)
    ##############################

    return predicted_class

from keras.models import Sequential
from keras.layers import Dense
 
model = Sequential()
model.add(Dense(4, activation='relu', input_shape=(4098,)))
model.add(Dense(1, activation='sigmoid'))

model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
# Load the image
#path = 'WhatsApp Image 2023-04-17 at 20.19.57.jpeg'
#image = cv2.imread(path) #enter path and reload this block 
# Preprocess the image

os.chdir("C:\\Users\\amirp\\Desktop\\Studies\\שנה ג\\פרויקט גמר\\Dataset\\Wilter- US dollar 1.v1i.yolov5pytorch\\train\\images")
picture_files = glob.glob("*.jpg")
first_10_pictures = picture_files[:30]
sum=0.0

for image in first_10_pictures:

    # # Load the image
    # path = 'cat.png'
    img = cv2.imread(image) #enter path and reload this block 
    # Preprocess the image
    feature_vector = preprocess_image(img)
    sum+=feature_vector
    
sum/=30.0

print(sum)

    with h5py.File('model.h5', 'r') as f:
    # Load the model architecture
        model = load_model(f, compile=False)
		
		
		
		import pandas as pd
import numpy as np
from keras.models import Sequential
from keras.layers import Dense

# Load the CSV file
df = pd.read_csv('BankNote_Authentication.csv')

# Extract the input features and target variable
X = df[['variance', 'skewness', 'curtosis', 'entropy']].values
y = df['class'].values

# Split the data into training and testing sets
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)

# Define the model
model = Sequential()
model.add(Dense(32, input_dim=X.shape[1], activation='relu'))
model.add(Dense(16, activation='relu'))
model.add(Dense(1, activation='sigmoid'))

# Compile the model
model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])

# Fit the model to the training data
model.fit(X_train, y_train, epochs=20, batch_size=300)

# Evaluate the model on the testing data
loss, accuracy = model.evaluate(X_test, y_test)
print("Accuracy on test set: {:.2f}%".format(accuracy * 100))


# Make predictions on new data
new_data = np.array([[2.5, -1.5, 0.5, -0.5], [-1.5, 2.5, -0.5, 0.5]])
predictions = model.predict(new_data)

# Print the predictions
print(predictions)
model.save('my_model.h5')









import cv2
import numpy as np
from keras.models import load_model
from sklearn.neighbors import KNeighborsClassifier
from scipy.stats import *
import h5py
from keras.models import load_model
from tensorflow import keras
import os
import glob


def preprocess_image(image):
    # Load the trained model
    with h5py.File("C:\\Users\\amirp\\Desktop\\Studies\\שנה ג\\Usd counterfeit fixed\\Usd counterfeit\\model.h5", 'r') as f:
    # Load the model architecture
        model = load_model(f, compile=False)

    # Resize the image to 64x64 pixels
    resized_image = cv2.resize(image, (64, 64))
    # Convert the image to grayscale
    gray_image = cv2.cvtColor(resized_image, cv2.COLOR_RGB2GRAY)
    # Flatten the image to a 1D array
    flattened_image = gray_image.flatten()
    # Normalize the image by dividing each pixel value by 255
    normalized_image = flattened_image / 255.0
    # Add two extra zeros to the end of the flattened image to make it a 1D array of four features
    feature_vector = np.concatenate([normalized_image, [0, 0]])
    # Return the flattened array of four features
    
    ##########################
    var = np.var(flattened_image)/1372
    skewness = skew(flattened_image.reshape(-1))
    kurt = kurtosis(flattened_image.reshape(-1))
    hist, _ = np.histogram(flattened_image, bins=256)
    entropy_val = entropy(hist)

    # Predict the class label for the image
    img_features = [[var, skewness, kurt, entropy_val]]
    predicted_class = model.predict(img_features)

    # Print the predicted class label
    print("Predicted Class Label:", predicted_class)
    print("Predicted Class Probabilities 0 for fake|1 for original")
    print("var:", var)
    print("ske:", skewness)
    print("kurt Class Label:", kurt)
    print("entropy_val:", entropy_val)
    
    # output the prediction
    if predicted_class <= 0.75: # it should be 0.6 because of the mean value of the training model.
        print("Fake note")
    else:
        print("Real note")
        
    detect_image(predicted_class,path)
    ##############################

    return predicted_class

num_of_photos = 50
os.chdir("C:\\Users\\amirp\\Desktop\\Studies\\שנה ג\\Usd counterfeit fixed\\Usd counterfeit\\fake")
picture_files = glob.glob("*.jpg")
photos = picture_files[:num_of_photos]
sum=0

for image in photos:

    # # Load the image
    # path = 'cat.png'
    img = cv2.imread(image) #enter path and reload this block 
    # Preprocess the image
    feature_vector = preprocess_image(img)
    sum+=feature_vector
    
sum/=num_of_photos

print(sum)